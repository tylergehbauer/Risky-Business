{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split #to for the train_test_split function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68812</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>346.76</td>\n",
       "      <td>RENT</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Jan-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20625.0</td>\n",
       "      <td>6798.0</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>5425.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68813</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>368.37</td>\n",
       "      <td>RENT</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jan-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>29.07</td>\n",
       "      <td>...</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87939.0</td>\n",
       "      <td>60350.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>62939.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68814</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>185.62</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Jan-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>14.86</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30592.0</td>\n",
       "      <td>18611.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>18492.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68815</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>1225.24</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Jan-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>9.96</td>\n",
       "      <td>...</td>\n",
       "      <td>98.2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1033574.0</td>\n",
       "      <td>95958.0</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>78634.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68816</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>350.36</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Jan-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>7.02</td>\n",
       "      <td>...</td>\n",
       "      <td>94.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251486.0</td>\n",
       "      <td>74835.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>63090.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "68812    10000.0    0.1502       346.76           RENT     26000.0   \n",
       "68813    12000.0    0.2727       368.37           RENT     63000.0   \n",
       "68814     5000.0    0.1992       185.62       MORTGAGE     52000.0   \n",
       "68815    40000.0    0.0646      1225.24       MORTGAGE    520000.0   \n",
       "68816    16000.0    0.1131       350.36       MORTGAGE     72000.0   \n",
       "\n",
       "      verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n",
       "68812     Source Verified  Jan-2019    low_risk          n   9.60  ...   \n",
       "68813        Not Verified  Jan-2019    low_risk          n  29.07  ...   \n",
       "68814     Source Verified  Jan-2019    low_risk          n  14.86  ...   \n",
       "68815            Verified  Jan-2019    low_risk          n   9.96  ...   \n",
       "68816            Verified  Jan-2019    low_risk          n   7.02  ...   \n",
       "\n",
       "       pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "68812            80.0               0.0                   0.0        0.0   \n",
       "68813            96.2               0.0                   0.0        0.0   \n",
       "68814           100.0               0.0                   1.0        0.0   \n",
       "68815            98.2              12.5                   0.0        0.0   \n",
       "68816            94.3               0.0                   1.0        0.0   \n",
       "\n",
       "       tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n",
       "68812          20625.0             6798.0        11300.0   \n",
       "68813          87939.0            60350.0        13500.0   \n",
       "68814          30592.0            18611.0         3600.0   \n",
       "68815        1033574.0            95958.0       100800.0   \n",
       "68816         251486.0            74835.0        23000.0   \n",
       "\n",
       "       total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n",
       "68812                      5425.0              N                     N  \n",
       "68813                     62939.0              N                     N  \n",
       "68814                     18492.0              N                     N  \n",
       "68815                     78634.0              N                     N  \n",
       "68816                     63090.0              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('Resources/LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = df.drop(columns=\"loan_status\") #x (features) is all columns without loan_status / x is what we will use to predict\n",
    "\n",
    "# Create our target\n",
    "y = df[\"loan_status\"] #y equals this specific column (target)/ what we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pd.get_dummies(X)\n",
    "#wouldn't let me scale without having all columns in rows display floats/integers\n",
    "#.get_dummies() converts categorical variables into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68817, 95)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low_risk     68470\n",
       "high_risk      347\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()\n",
    "#low_risk is marjoity\n",
    "#high_risk is minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51612, 95)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, #column created above\n",
    "                                                    y, #column created above\n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "\n",
    "#using this data to train and test to see if predictions of actual data is accurate (if so, we can predict new data)\n",
    "\n",
    "#around 70% of the data is going to training,and around 30% going to testing\n",
    "\n",
    "X_train.shape #as you can see, 51612 out of 68817 rows is around 75% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "\n",
    "#Scaling is used so that one column doesn't have too much bias\n",
    "ds = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "\n",
    "X_scaler = ds.fit(X_train) #using it on X_train (training dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learners\n",
    "\n",
    "In this section, you will compare two ensemble algorithms to determine which algorithm results in the best performance. You will train a Balanced Random Forest Classifier and an Easy Ensemble classifier . For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. Train the model using the training data. \n",
    "2. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "3. Display the confusion matrix from sklearn.metrics.\n",
    "4. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "5. For the Balanced Random Forest Classifier only, print the feature importance sorted in descending order (most important feature to least important) along with the feature score\n",
    "\n",
    "Note: Use a random state of 1 for each algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "#Says to use random state of 1 for each alogrithm\n",
    "#Instructions also stated, for the ensemble learners, use 100 estimators for both models.\n",
    "balanced_rf = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "balanced_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871246640962729"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred_balanced_rf = balanced_rf.predict(X_test_scaled)\n",
    "balanced_accuracy_score(y_test, y_pred_balanced_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   58,    29],\n",
       "       [ 1582, 15536]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_balanced_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk      0.035     0.667     0.908     0.067     0.778     0.590        87\n",
      "   low_risk      0.998     0.908     0.667     0.951     0.778     0.620     17118\n",
      "\n",
      "avg / total      0.993     0.906     0.668     0.946     0.778     0.619     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred_balanced_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <td>0.073767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rec_int</th>\n",
       "      <td>0.063903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <td>0.060733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pymnt</th>\n",
       "      <td>0.058112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <td>0.049518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.024581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_prncp</th>\n",
       "      <td>0.020399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0.018626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bal_bc</th>\n",
       "      <td>0.018379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_d_Jan-2019</th>\n",
       "      <td>0.017480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "total_rec_prncp     0.073767\n",
       "total_rec_int       0.063903\n",
       "total_pymnt_inv     0.060733\n",
       "total_pymnt         0.058112\n",
       "last_pymnt_amnt     0.049518\n",
       "int_rate            0.024581\n",
       "out_prncp           0.020399\n",
       "dti                 0.018626\n",
       "max_bal_bc          0.018379\n",
       "issue_d_Jan-2019    0.017480"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importance = balanced_rf.feature_importances_ #this function lets us see most important features\n",
    "\n",
    "#I create a dataframe to easily visualize and sort\n",
    "importance_df = pd.DataFrame(importance, index = X_train.columns, columns = ['importance'])#makes x_train columns index\n",
    "#labels the the column importance\n",
    "\n",
    "importance_df = importance_df.sort_values(by = 'importance', ascending=False) #sorts values in descending order\n",
    "\n",
    "importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Classifier\n",
    "ez = EasyEnsembleClassifier(n_estimators=100,random_state=1)\n",
    "ez.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254565671948463"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred_ez = ez.predict(X_test_scaled) \n",
    "balanced_accuracy_score(y_test, y_pred_ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   79,     8],\n",
       "       [  978, 16140]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred_ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk      0.075     0.908     0.943     0.138     0.925     0.853        87\n",
      "   low_risk      1.000     0.943     0.908     0.970     0.925     0.859     17118\n",
      "\n",
      "avg / total      0.995     0.943     0.908     0.966     0.925     0.859     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred_ez, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*:\n",
    "Balanced Random Forest:0.7871246640962729\n",
    "\n",
    "Easy Ensemble Classifier:0.9254565671948463\n",
    "\n",
    "*Recall*:\n",
    "Balanced Random Forest:0.906 \n",
    "\n",
    "Easy Ensemble Classifier: 0.943 \n",
    "\n",
    "*Geometric*:\n",
    "Balanced Random Forest: 0.778 \n",
    "\n",
    "Easy Ensemble Classifier:0.925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Questions\n",
    "\n",
    "1. Which model had the best balanced accuracy score?\n",
    "\n",
    "   *Easy Ensemble Classifier* had the best balanced accurcy score with a score of .925\n",
    "   \n",
    "2. Which model had the best recall score?\n",
    "\n",
    "    *Easy Ensemble Classifier* had the best recall score with a score of .943\n",
    "\n",
    "3. Which model had the best geometric mean score?\n",
    "\n",
    "    *Easy Ensemble Classifier* had best Geometric mean score with a of .925\n",
    "\n",
    "4. What are the top three features?\n",
    "\n",
    "    Top 3 features were (values in dataframe above)\n",
    "    1. total_rec_prncp\n",
    "    2. total_rec_int\n",
    "    3. total_pymnt_inv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
